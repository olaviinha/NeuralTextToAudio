{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zDb5oYf3aChsGJaZ752dhmhP9NhZKs8w",
      "authorship_tag": "ABX9TyMTCAjmXzbcCQvNKBWNAONs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToAudio/blob/main/AudioLDM_pub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">AudioLDM<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Text-to-audio</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToAudio\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Generate audio from text-prompt using [AudioLDM](https://github.com/haoheliu/AudioLDM)."
      ],
      "metadata": {
        "id": "GBgr33OisX3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Display instructions and tips\n",
        "%%html\n",
        "<style type=\"text/css\">\n",
        "div, ul.tips {\n",
        "  font-size: 17px;\n",
        "  line-height: 25px;\n",
        "}\n",
        "ul.tips { \n",
        "  max-width: 70%;\n",
        "  margin-left: 0;\n",
        "  padding-left: 20px;\n",
        "}\n",
        "ul.tips li {\n",
        "  margin-bottom: 7px;\n",
        "}\n",
        "ul.tips li code { \n",
        "  font-size: 16px;\n",
        "  background: #2c2c2c; \n",
        "  padding: 2px 5px; \n",
        "}\n",
        "ul.tips li ul.sublist li {\n",
        "  line-height: auto;\n",
        "  margin-bottom: 5px;\n",
        "}\n",
        "h2, div {\n",
        "  margin-top: 30px;\n",
        "  margin-bottom: 20px;\n",
        "}\n",
        ".italic {\n",
        "  font-style: italic;\n",
        "}\n",
        "</style>\n",
        "<h2>Notebook usage</h2>\n",
        "<ul class=\"tips\">\n",
        "  <li>All directory and file paths should be relative to your Google Drive root (My Drive). E.g. <code>output_dir</code> value should be <code>Music/AI-Generated-Sounds</code> if you have a directory called <i>Music</i> in your Drive, containing a subdirectory called <i>AI-Generated-Sounds</i>. All paths are case-sensitive.</li>\n",
        "  <li>Should you opt not to mount Google Drive, directory <i>faux_drive</i> (<code>/content/faux_drive</code>) found in the Files browser of the Colab runtime works as if it was your <i>My Drive</i>. You may use it to upload/download files via Colab's own Files browser pretending it's your Google Drive.</li>\n",
        "  <li>Model <code>audioldm-full-l</code> requires Premium GPU. Other models run with standard GPU.</li>\n",
        "  <li><code>local_models_dir</code> (optional but recommended) will save the used checkpoints in your Google Drive and/or use them from there if already available. This will speed up setup significantly next times you use this notebook.</li>\n",
        "  <li><code>output_dir</code> is where the generated WAV files will be saved.</li>\n",
        "  <li><code>batch</code> will just repeat whatever you're generating that many times.</li>\n",
        "  <li>If <code>seed</code> is set to 0 (zero), a random seed will be used.</li>\n",
        "  <li>You may use <code>;</code> in the <code>prompt</code> field as a separator, in which case a separate audio file will be generated for each semicolon-separated prompt in a single run.</li>\n",
        "  <li>If you use <code>init_audio_file</code> (path to an existing audio file in your Google Drive), the notebook will try to guess what you want to do according to other parameters you have given, as follows:</li>\n",
        "  <li><b>Audio-to-Audio generation</b>\n",
        "    <ul class=\"sublist\">\n",
        "      <li>Leave <code>prompt</code> field empty.</li>\n",
        "      <li>Leave <code>style_strength</code> at zero.</li>\n",
        "      <!-- <li>Leave <code>superresolution</code> unchecked.</li> -->\n",
        "    </ul>\n",
        "  </li>\n",
        "  <li><b>Style Transfer</b>\n",
        "    <ul class=\"sublist\">\n",
        "      <li>Fill <code>prompt</code> field.</li>\n",
        "      <li>Set <code>style_strength</code> (greater than zero).</li>\n",
        "      <!-- <li>Leave <code>superresolution</code> unchecked.</li> -->\n",
        "    </ul>\n",
        "  </li>\n",
        "  <!-- <li><b>Super-restolution</b>\n",
        "    <ul class=\"sublist\">\n",
        "      <li>Check <code>superresolution</code> checkbox.</li>\n",
        "      <li><code>prompt</code> and <code>style_strength</code> are automatically ignored.\n",
        "  </li> -->\n",
        "</ul>\n",
        "\n",
        "<h2>Prompt tips</h2>\n",
        "<div>Naturally a <i>good</i> prompt depends on what you're after, but generally:</div>\n",
        "<ul class=\"tips\">\n",
        "  <li>Consider adding more detailed description of what kind of sound you want (add adjectives, etc.).</li>\n",
        "  <li>For better quality, you may try some additional keywords generally associated with better quality, for example\n",
        "    <ul class=\"sublist\">\n",
        "      <li><i>in studio</i></li>\n",
        "      <li><i>studio recording</i></li>\n",
        "      <li><i>high quality</i></li>\n",
        "      <li><i>album</i> (for music)</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "</ul>"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zrf6Dy2DTTSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = ['https://github.com/haoheliu/AudioLDM.git']\n",
        "pip_packages = ''\n",
        "apt_packages = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "local_models_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "use_checkpoint = \"audioldm-full-s-v2\" #@param [\"audioldm-s-full\", \"audioldm-full-l\", \"audioldm-full-s-v2\"]\n",
        "\n",
        "\n",
        "if use_checkpoint == 'audioldm-s-full':\n",
        "  ckpt_url = 'https://zenodo.org/record/7600541/files/'+use_checkpoint+'.ckpt?download=1'\n",
        "else:\n",
        "  ckpt_url = 'https://zenodo.org/record/7698295/files/'+use_checkpoint+'.ckpt?download=1'\n",
        "  \n",
        "use_ckpt = use_checkpoint+'.ckpt'\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "if pip_packages != '':\n",
        "  !pip -q install {pip_packages}\n",
        "if apt_packages != '':\n",
        "  !apt-get update && apt-get install {apt_packages}\n",
        "\n",
        "import sys, time, ntpath, string, random, librosa, librosa.display, IPython, shutil, math, psutil, datetime, requests, pytz\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from datetime import timedelta\n",
        "\n",
        "# Print colors\n",
        "class c:\n",
        "  title = '\\033[96m'\n",
        "  ok = '\\033[92m'\n",
        "  okb = '\\033[94m'\n",
        "  warn = '\\033[93m'\n",
        "  fail = '\\033[31m'\n",
        "  endc = '\\033[0m'\n",
        "  bold = '\\033[1m'\n",
        "  dark = '\\33[90m'\n",
        "  u = '\\033[4m'\n",
        "\n",
        "def op(typex, msg, value='', time=False):\n",
        "  if time == True:\n",
        "    stamp = timestamp(human_readable=True)\n",
        "    typex = c.dark+stamp+' '+typex\n",
        "  if value != '':\n",
        "    print(typex+msg+c.endc, end=' ')\n",
        "    print(value)\n",
        "  else:\n",
        "    print(typex+msg+c.endc)\n",
        "\n",
        "def gen_id(type='short'):\n",
        "  id = ''\n",
        "  if type == 'timestamp':\n",
        "    id = timestamp()\n",
        "  if type == 'short':\n",
        "    id = requests.get('https://api.inha.asia/k/?type=short').text\n",
        "  if type == 'long':\n",
        "    id = requests.get('https://api.inha.asia/k').text\n",
        "  return id\n",
        "\n",
        "def timestamp(no_slash=False, human_readable=False, helsinki_time=True, date_only=False):\n",
        "  if helsinki_time == True:\n",
        "    dt = datetime.datetime.now(pytz.timezone('Europe/Helsinki'))\n",
        "  else:\n",
        "    dt = datetime.datetime.now()\n",
        "  if no_slash == True:\n",
        "    dt = dt.strftime(\"%Y%m%d%H%M%S\")\n",
        "  else:\n",
        "    if human_readable == True:\n",
        "      dt = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    else:\n",
        "      if date_only == True:\n",
        "        dt = dt.strftime(\"%Y-%m-%d\")\n",
        "      else:\n",
        "        dt = dt.strftime(\"%Y-%m-%d_%H%M%S\")\n",
        "  return dt;\n",
        "\n",
        "def fix_path(path, add_slash=False):\n",
        "  if path.endswith('/'):\n",
        "    path = path #path[:-1]\n",
        "  if not path.endswith('/'):\n",
        "    path = path+\"/\"\n",
        "  if path.startswith('/') and add_slash == True:\n",
        "    path = path[1:]\n",
        "  return path\n",
        "  \n",
        "def path_leaf(path):\n",
        "  head, tail = ntpath.split(path)\n",
        "  return tail or ntpath.basename(head)\n",
        "\n",
        "def path_dir(path):\n",
        "  return path.replace(path_leaf(path), '')\n",
        "\n",
        "def path_ext(path, only_ext=False):\n",
        "  filename, extension = os.path.splitext(path)\n",
        "  if only_ext == True:\n",
        "    extension = extension[1:]\n",
        "  return extension\n",
        "\n",
        "def basename(path):\n",
        "  filename = os.path.basename(path).strip()#.replace(\" \", \"_\")\n",
        "  filebase = os.path.splitext(filename)[0]\n",
        "  return filebase\n",
        "\n",
        "def slug(s):\n",
        "  valid_chars = \"-_. %s%s\" % (string.ascii_letters, string.digits)\n",
        "  file = ''.join(c for c in s if c in valid_chars)\n",
        "  file = file.replace(' ','_')\n",
        "  return file\n",
        "  \n",
        "def fetch(url, save_as):\n",
        "  headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
        "  try:\n",
        "    r = requests.get(url, stream=True, headers=headers, timeout=5)\n",
        "    if r.status_code == 200:\n",
        "      with open(save_as, 'wb') as f:\n",
        "        r.raw.decode_content = True\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "      resp = r.status_code\n",
        "    else:\n",
        "      resp = 0\n",
        "  except requests.exceptions.ConnectionError as e:\n",
        "    r = 0\n",
        "    resp = r\n",
        "  return resp\n",
        "\n",
        "def list_audio(path, midi=False):\n",
        "  audiofiles = []\n",
        "  for ext in ('*.wav', '*.aiff', '*.aif', '*.caf' '*.flac', '*.mp3', '*.m4a', '*.ogg', '*.WAV', '*.AIFF', '*.AIF', '*.CAF', '*.FLAC', '*.MP3', '*.OGG'):\n",
        "    audiofiles.extend(glob(join(path, ext)))\n",
        "  if midi is True:\n",
        "    for ext in ('*.mid', '*.midi', '*.MID', '*.MIDI'):\n",
        "      audiofiles.extend(glob(join(path, ext)))\n",
        "  audiofiles.sort()\n",
        "  return audiofiles\n",
        "\n",
        "def audio_player(input, sr=44100, limit_duration=2):\n",
        "  if type(input) != np.ndarray:\n",
        "    input, sr = librosa.load(input, sr=None, mono=False)\n",
        "  if limit_duration > 0:\n",
        "    last_sample = math.floor(limit_duration*60*sr)\n",
        "    if input.shape[-1] > last_sample:\n",
        "      input = input[:last_sample, :last_sample]\n",
        "      op(c.warn, 'WARN! Playback of below audio player is limited to first '+str(limit_duration)+' minutes to prevent Colab from crashing.\\n')\n",
        "  IPython.display.display(IPython.display.Audio(input, rate=sr))\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive == True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive/'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  os.mkdir('/content/faux_drive')\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if mount_drive == False:\n",
        "  local_models_dir = ''\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e {install_dir}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "if not os.path.isdir(dir_tmp): os.mkdir(dir_tmp)\n",
        "\n",
        "use_ckpt_path = os.path.expanduser('~')+'/.cache/audioldm/'\n",
        "\n",
        "if not os.path.isdir(use_ckpt_path):\n",
        "  os.makedirs(use_ckpt_path)\n",
        "\n",
        "if local_models_dir != '':\n",
        "  models_dir = drive_root+fix_path(local_models_dir)\n",
        "  if not os.path.isdir(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "  # for ckpt_url in ckpt_urls:\n",
        "  #   use_ckpt = ckpt_url.split('files/')[1].split('?')[0]\n",
        "  if os.path.isfile(models_dir+use_ckpt):\n",
        "    op(c.title, 'Fetching local ckpt:', models_dir.replace(drive_root, '')+use_ckpt)\n",
        "    shutil.copy(models_dir+use_ckpt, use_ckpt_path+use_ckpt)\n",
        "    op(c.ok, 'Done.')\n",
        "  else:\n",
        "    op(c.warn, 'Downloading '+use_ckpt+' to ', models_dir.replace(drive_root, ''))\n",
        "    !wget {ckpt_url} -O {models_dir}{use_ckpt}\n",
        "    shutil.copy(models_dir+use_ckpt, use_ckpt_path+use_ckpt)\n",
        "    op(c.ok, 'Done.')\n",
        "else:\n",
        "  # for ckpt_url in ckpt_urls:\n",
        "  #   use_ckpt = ckpt_url.split('files/')[1].split('?')[0]\n",
        "  models_dir = use_ckpt_path\n",
        "  op(c.warn, 'Downloading', use_ckpt)\n",
        "  !wget {ckpt_url} -O {models_dir}{use_ckpt}\n",
        "  shutil.copy(models_dir+use_ckpt, use_ckpt_path+use_ckpt)\n",
        "  op(c.ok, 'Done.')\n",
        "\n",
        "ckpt_path = use_ckpt_path+use_ckpt\n",
        "op(c.title, 'Build model', ckpt_path)\n",
        "sys.path.append('/content/AudioLDM/audioldm/')\n",
        "from audioldm import text_to_audio, style_transfer, super_resolution_and_inpainting, build_model, latent_diffusion\n",
        "audioldm = build_model(ckpt_path=ckpt_path, model_name=use_checkpoint)\n",
        "\n",
        "def round_to_multiple(number, multiple):\n",
        "  x = multiple * round(number / multiple)\n",
        "  if x == 0: x = multiple\n",
        "  return x\n",
        "\n",
        "def text2audio(text, duration, audio_path, guidance_scale, random_seed, n_candidates, steps):\n",
        "  waveform = text_to_audio(\n",
        "    audioldm,\n",
        "    text,\n",
        "    audio_path,\n",
        "    random_seed,\n",
        "    duration=duration,\n",
        "    guidance_scale=guidance_scale,\n",
        "    ddim_steps=steps,\n",
        "    n_candidate_gen_per_text=int(n_candidates)\n",
        "  )\n",
        "  if(len(waveform) == 1):\n",
        "    waveform = waveform[0]\n",
        "  return waveform\n",
        "\n",
        "def styleaudio(text, duration, audio_path, strength, guidance_scale, random_seed, steps):\n",
        "  waveform = style_transfer(\n",
        "    audioldm,\n",
        "    text,\n",
        "    audio_path,\n",
        "    strength,\n",
        "    random_seed,\n",
        "    duration=duration,\n",
        "    guidance_scale=guidance_scale,\n",
        "    ddim_steps=steps,\n",
        "  )\n",
        "  if(len(waveform) == 1):\n",
        "    waveform = waveform[0]\n",
        "  return waveform\n",
        "\n",
        "\n",
        "# time_mask_ratio_start_and_end=(0.10, 0.15), # regenerate the 10% to 15% of the time steps in the spectrogram\n",
        "# time_mask_ratio_start_and_end=(1.0, 1.0), # no inpainting\n",
        "# freq_mask_ratio_start_and_end=(0.75, 1.0), # regenerate the higher 75% to 100% mel bins\n",
        "# freq_mask_ratio_start_and_end=(1.0, 1.0), # no super-resolution\n",
        "def superres(text, duration, audio_path, guidance_scale, random_seed, n_candidates, steps):\n",
        "  waveform = super_resolution_and_inpainting(\n",
        "    audioldm,\n",
        "    text,\n",
        "    audio_path,\n",
        "    random_seed,\n",
        "    ddim_steps=steps,\n",
        "    duration=duration,\n",
        "    guidance_scale=guidance_scale,\n",
        "    n_candidate_gen_per_text=n_candidates,\n",
        "    freq_mask_ratio_start_and_end=(0.75, 1.0)\n",
        "  )\n",
        "  if(len(waveform) == 1):\n",
        "    waveform = waveform[0]\n",
        "  return waveform\n",
        "\n",
        "\n",
        "prompt_list = []\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "print()\n",
        "op(c.title, 'Using:', use_ckpt, time=True)\n",
        "op(c.ok, 'Setup finished.', time=True)\n",
        "print()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-l7u34qYZ07a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate audio"
      ],
      "metadata": {
        "id": "WeGOwgMJlgXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\" #@param {type:\"string\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "duration = 5 #@param {type:\"slider\", min:2.5, max:30, step:2.5}\n",
        "guidance_scale = 2.5 #@param {type:\"slider\", min:2, max:5, step:0.5}\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "candidates = 3 #@param {type:\"slider\", min:2, max:5, step:1}\n",
        "batch = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown <b>Style Transfer & Audio-to-Audio</b> settings â€“ Ignore these settings if you just want to generate audio by text prompt.\n",
        "init_audio_file = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# what_to_do = \"Audio-to-audio generation\" #@param [\"Audio-to-audio generation\", \"Super-resolution\", \"Style Transfer\"]\n",
        "what_to_do = None\n",
        "style_strength = 0 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "superresolution = False #@ param {type:\"boolean\"}\n",
        "\n",
        "if what_to_do == 'Audio-to-audio-generation': action = 'audio2audio'\n",
        "if what_to_do == 'Super-resolution': action = 'superres'\n",
        "if what_to_do == 'Style Transfer': action = 'style'\n",
        "if what_to_do == 'Inpaint': action = 'inpaint'\n",
        "\n",
        "ddim_steps = 200\n",
        "og_seed = seed\n",
        "og_duration = duration\n",
        "uniq_id = gen_id()\n",
        "sr = 16000\n",
        "\n",
        "# Prompt/input\n",
        "if ';' in prompt:\n",
        "  inputs = prompt.split(';')\n",
        "elif prompt == 'prompt_list':\n",
        "  inputs = prompt_list\n",
        "else:\n",
        "  inputs = [prompt]\n",
        "inputs = [x.strip() for x in inputs]\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  if mount_drive is True:\n",
        "    dir_out = dir_tmp\n",
        "  if mount_drive is False:\n",
        "    dir_out = drive_root+'generated-audio'\n",
        "    if not os.path.isdir(dir_out):\n",
        "      os.mkdir(dir_out)\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "\n",
        "if batch == 0: batch = 1  \n",
        "inputs = inputs * batch\n",
        "\n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "action = 'generate'\n",
        "init_path = None\n",
        "\n",
        "for i, input in enumerate(inputs, 1):\n",
        "  \n",
        "  ndx_info = str(i)+'/'+str(total)+' '\n",
        "  print()\n",
        "\n",
        "  if init_audio_file != '':\n",
        "    if os.path.isfile(drive_root+init_audio_file):\n",
        "      init_path = drive_root+init_audio_file\n",
        "      if superresolution is True:\n",
        "        action = 'superres'\n",
        "      elif style_strength > 0:\n",
        "        init_filename = path_leaf(init_path)\n",
        "        op(c.title, ndx_info+'Styling audio:', init_path.replace(drive_root, ''), time=True)\n",
        "        op(c.title, 'With prompt:', input, time=True)\n",
        "        action = 'style'\n",
        "      else:\n",
        "        op(c.title, ndx_info+'Audio-to-audio generation:', init_path.replace(drive_root, ''), time=True)\n",
        "        # op(c.title, 'With prompt:', input, time=True)\n",
        "        input = None\n",
        "        action = 'audio2audio'\n",
        "      # Trim duration if init duration is shorter than given duration\n",
        "      init_y, init_sr = librosa.load(init_path, sr=None, mono=True)\n",
        "      init_duration = librosa.get_duration(init_y, init_sr)\n",
        "      duration = round_to_multiple(init_duration, 2.5) if init_duration < og_duration else duration\n",
        "      \n",
        "    else:\n",
        "      op(c.fail, ndx_info+'Init audio file not found!', time=True)\n",
        "      sys.exit('Make sure init_audio_file is a valid audio file and a valid file path relative to your My Drive.')\n",
        "  else:\n",
        "    op(c.title, ndx_info+'Generating audio:', input, time=True)\n",
        "\n",
        "  if og_seed == 0: seed = int(time.time())\n",
        "\n",
        "  if action == 'generate':\n",
        "    file_out = dir_out+uniq_id+'__'+slug(input)[:60]+'_'+str(i).zfill(3)+'.wav'\n",
        "    generated_audio = text2audio(input, duration, None, guidance_scale, seed, candidates, ddim_steps)\n",
        "  elif action == 'audio2audio':\n",
        "    file_out = dir_out+uniq_id+'__'+basename(init_path)+'_'+str(i).zfill(3)+'.wav'\n",
        "    generated_audio = text2audio('placeholder', duration, init_path, guidance_scale, seed, candidates, ddim_steps)\n",
        "  elif action == 'superres':\n",
        "    file_out = dir_out+uniq_id+'__'+basename(init_path)+'_'+str(i).zfill(3)+'.wav'\n",
        "    y, sr = librosa.load(init_path, sr=None)\n",
        "    duration = librosa.get_duration(y, sr=sr)\n",
        "    if duration > 30: duration = 30\n",
        "    generated_audio = superres(None, duration, init_path, guidance_scale, seed, candidates, ddim_steps)\n",
        "  elif action == 'style':\n",
        "    file_out = dir_out+uniq_id+'__'+basename(init_path)+'_'+slug(input)[:60]+'_'+str(i).zfill(3)+'.wav'\n",
        "    generated_audio = styleaudio(input, duration, init_path, style_strength, guidance_scale, seed, ddim_steps)\n",
        "  else:\n",
        "    op(c.fail, 'Something went wrong.')\n",
        "    sys.exit()\n",
        "\n",
        "  \n",
        "  sf.write(file_out, generated_audio.T, sr, subtype='PCM_24')\n",
        "  if os.path.isfile(file_out):\n",
        "    audio_player(generated_audio, sr=sr)\n",
        "    print()\n",
        "    op(c.ok, 'Saved as', file_out.replace(drive_root, ''), time=True)\n",
        "  else:\n",
        "    op(c.fail, 'Error saving', file_out.replace(drive_root, ''), time=True)\n",
        "  \n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')"
      ],
      "metadata": {
        "id": "Znu4P-Gtsdrr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}