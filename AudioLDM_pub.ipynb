{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zDb5oYf3aChsGJaZ752dhmhP9NhZKs8w",
      "authorship_tag": "ABX9TyP8k83FiF7XhuH0RExla5kU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralTextToAudio/blob/main/AudioLDM_pub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">AudioLDM<font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font color=\"#999\" size=\"4\">Text-to-audio</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/NeuralTextToAudio\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a>\n",
        "\n",
        "Generate audio from text-prompt using [AudioLDM](https://github.com/haoheliu/AudioLDM).\n",
        "\n",
        "#### Tips\n",
        "- All directory and file paths should be relative to your Google Drive root (My Drive), e.g. `output_dir` value should be `music/ai-generated-sounds` if you have a directory called _music_ in your Drive, containing a subdirectory called _ai-generated-sounds_.\n",
        "- `local_models_dir` is optional but recommended. It will store models in your Google Drive and/or use them from there if already available.\n",
        "- `output_dir` is where the generated WAV files will be saved.\n",
        "- `batch` will just repeat whatever you're generating that many times.\n",
        "- If `seed` is set to 0 (zero), a random seed will be used.\n",
        "- You may use `;` in the `prompt` field as a separator, in which case a separate audio file will be generated for each prompt in a single run.\n",
        "- Use `init_audio_file` (path to an existing audio file in your Google Drive) and `strength` only if you want to do Style Transfer, i.e. transfer the prompt generated style to your existing audio file. If you just want to generate new audio files by prompt, ignore these two settings."
      ],
      "metadata": {
        "id": "GBgr33OisX3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisites.<br>\n",
        "#@markdown <small>Mounting Drive will enable this notebook to save outputs directly to your Drive. Otherwise you will need to copy/download them manually from this notebook.</small>\n",
        "\n",
        "force_setup = False\n",
        "repositories = ['https://github.com/haoheliu/AudioLDM.git']\n",
        "pip_packages = ''\n",
        "apt_packages = ''\n",
        "mount_drive = True #@param {type:\"boolean\"}\n",
        "skip_setup = False #@ param {type:\"boolean\"}\n",
        "local_models_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# Download the repo from Github\n",
        "import os\n",
        "from google.colab import output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%cd /content/\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb') and force_setup == False:\n",
        "  !pip -q install import-ipynb {pip_packages}\n",
        "  if apt_packages != '':\n",
        "    !apt-get update && apt-get install {apt_packages}\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if mount_drive == True:\n",
        "  if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    drive_root = '/content/drive/My Drive'\n",
        "  if not os.path.isdir('/content/mydrive'):\n",
        "    os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "    drive_root = '/content/mydrive/'\n",
        "  drive_root_set = True\n",
        "else:\n",
        "  create_dirs(['/content/faux_drive'])\n",
        "  drive_root = '/content/faux_drive/'\n",
        "\n",
        "if mount_drive == False:\n",
        "  local_models_dir = ''\n",
        "\n",
        "if len(repositories) > 0 and skip_setup == False:\n",
        "  for repo in repositories:\n",
        "    %cd /content/\n",
        "    install_dir = fix_path('/content/'+path_leaf(repo).replace('.git', ''))\n",
        "    repo = repo if '.git' in repo else repo+'.git'\n",
        "    !git clone {repo}\n",
        "    if os.path.isfile(install_dir+'setup.py') or os.path.isfile(install_dir+'setup.cfg'):\n",
        "      !pip install -e {install_dir}\n",
        "    if os.path.isfile(install_dir+'requirements.txt'):\n",
        "      !pip install -r {install_dir}/requirements.txt\n",
        "\n",
        "if len(repositories) == 1:\n",
        "  %cd {install_dir}\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "import time, sys\n",
        "from datetime import timedelta\n",
        "\n",
        "use_model_path = '/content/AudioLDM/ckpt/'\n",
        "use_model = 'ldm_trimmed.ckpt'\n",
        "\n",
        "if not os.path.isdir(use_model_path):\n",
        "  os.mkdir(use_model_path)\n",
        "if not os.path.isfile(use_model_path+use_model):\n",
        "  if local_models_dir != '':\n",
        "    models_dir = drive_root+fix_path(local_models_dir)\n",
        "    if not os.path.isdir(models_dir):\n",
        "      os.mkdir(models_dir)\n",
        "    if os.path.isfile(models_dir+use_model):\n",
        "      shutil.copy(models_dir+use_model, use_model_path+use_model)\n",
        "    else:\n",
        "      #!wget https://huggingface.co/ckpt/audioldm/resolve/main/ldm_trimmed.ckpt -O {models_dir}ldm_trimmed.ckpt\n",
        "      !wget https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation/resolve/main/ckpt/ldm_trimmed.ckpt {models_dir}ldm_trimmed.ckpt\n",
        "      shutil.copy(models_dir+use_model, use_model_path+use_model)\n",
        "  else:\n",
        "    #!wget https://huggingface.co/ckpt/audioldm/resolve/main/ldm_trimmed.ckpt -O /content/AudioLDM/ckpt/ldm_trimmed.ckpt\n",
        "    !wget https://huggingface.co/spaces/haoheliu/audioldm-text-to-audio-generation/resolve/main/ckpt/ldm_trimmed.ckpt -O /content/AudioLDM/ckpt/ldm_trimmed.ckpt\n",
        "\n",
        "import sys\n",
        "\n",
        "# sys.path.append('/content/AudioLDM')\n",
        "sys.path.append('/content/AudioLDM/audioldm')\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from audioldm import text_to_audio, style_transfer, build_model, latent_diffusion\n",
        "\n",
        "audioldm = build_model(ckpt_path=use_model_path+use_model)\n",
        "\n",
        "def round_to_multiple(number, multiple):\n",
        "  x = multiple * round(number / multiple)\n",
        "  if x == 0: x = multiple\n",
        "  return x\n",
        "\n",
        "def text2audio(text, duration, guidance_scale, random_seed, n_candidates, steps):\n",
        "  waveform = text_to_audio(\n",
        "    audioldm,\n",
        "    text,\n",
        "    random_seed,\n",
        "    duration=duration,\n",
        "    guidance_scale=guidance_scale,\n",
        "    ddim_steps=steps,\n",
        "    n_candidate_gen_per_text=int(n_candidates)\n",
        "  )\n",
        "  if(len(waveform) == 1):\n",
        "    waveform = waveform[0]\n",
        "  return waveform\n",
        "\n",
        "def styleaudio(text, duration, audio_path, strength, guidance_scale, random_seed, steps):\n",
        "  waveform = style_transfer(\n",
        "    audioldm,\n",
        "    text,\n",
        "    audio_path,\n",
        "    strength,\n",
        "    random_seed,\n",
        "    duration=duration,\n",
        "    guidance_scale=guidance_scale,\n",
        "    ddim_steps=steps,\n",
        "  )\n",
        "  if(len(waveform) == 1):\n",
        "    waveform = waveform[0]\n",
        "  return waveform\n",
        "\n",
        "prompt_list = []\n",
        "\n",
        "output.clear()\n",
        "# !nvidia-smi\n",
        "op(c.ok, 'Setup finished.', time=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-l7u34qYZ07a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Generate audio\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "output_dir = \"\" #@param {type:\"string\"}\n",
        "duration = 5 #@param {type:\"slider\", min:2.5, max:30, step:2.5}\n",
        "guidance_scale = 2.5 #@param {type:\"slider\", min:2, max:5, step:0.5}\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "candidates = 3 #@param {type:\"slider\", min:2, max:5, step:1}\n",
        "batch = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown <b>Style Transfer settings</b> – use these only if you want to do style transfer. Otherwise ignore.\n",
        "\n",
        "init_audio_file = \"\" #@param {type:\"string\"}\n",
        "style_strength = 0 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "ddim_steps = 200\n",
        "og_seed = seed\n",
        "og_duration = duration\n",
        "uniq_id = gen_id()\n",
        "sr = 16000\n",
        "\n",
        "# Prompt/input\n",
        "if ';' in prompt:\n",
        "  inputs = prompt.split(';')\n",
        "elif prompt == 'prompt_list':\n",
        "  inputs = prompt_list\n",
        "else:\n",
        "  inputs = [prompt]\n",
        "inputs = [x.strip() for x in inputs]\n",
        "\n",
        "# Output\n",
        "if output_dir == '':\n",
        "  dir_out = dir_tmp\n",
        "else:\n",
        "  if not os.path.isdir(drive_root+output_dir):\n",
        "    os.mkdir(drive_root+output_dir)\n",
        "  dir_out = drive_root+fix_path(output_dir)\n",
        "\n",
        "if batch == 0: batch = 1  \n",
        "inputs = inputs * batch\n",
        "\n",
        "timer_start = time.time()\n",
        "total = len(inputs)\n",
        "action = 'generate'\n",
        "\n",
        "for i, input in enumerate(inputs, 1):\n",
        "  file_out = dir_out+uniq_id+'__'+slug(input)[:16]+'_'+str(i).zfill(3)+'.wav'\n",
        "  ndx_info = str(i)+'/'+str(total)+' '\n",
        "  print()\n",
        "\n",
        "  if init_audio_file != '':\n",
        "    if os.path.isfile(drive_root+init_audio_file):\n",
        "      init_path = drive_root+init_audio_file\n",
        "      init_filename = path_leaf(init_path)\n",
        "      op(c.title, ndx_info+'Styling audio:', init_path.replace(drive_root, ''), time=True)\n",
        "      op(c.title, 'With prompt:', input, time=True)\n",
        "      action = 'style'\n",
        "\n",
        "      # Trim duration if init duration is shorter than given duration\n",
        "      init_y, init_sr = librosa.load(init_path, sr=None, mono=True)\n",
        "      init_duration = librosa.get_duration(init_y, init_sr)\n",
        "      duration = round_to_multiple(init_duration, 2.5) if init_duration < og_duration else duration\n",
        "      \n",
        "    else:\n",
        "      op(c.fail, ndx_info+'Init audio file not found!', time=True)\n",
        "      sys.exit('Make sure init_audio_file is a valid a valid audio file and a valid file path relative to your My Drive.')\n",
        "  else:\n",
        "    op(c.title, ndx_info+'Generating audio:', input, time=True)\n",
        "\n",
        "  if og_seed == 0: seed = int(time.time())\n",
        "\n",
        "  if action == 'generate':\n",
        "    generated_audio = text2audio(input, duration, guidance_scale, seed, candidates, ddim_steps)\n",
        "  elif action == 'style':\n",
        "    generated_audio = styleaudio(input, duration, init_path, style_strength, guidance_scale, seed, ddim_steps)\n",
        "  else:\n",
        "    op(c.fail, 'Something went wrong.')\n",
        "    sys.exit()\n",
        "\n",
        "  sf.write(file_out, generated_audio.T, sr, subtype='PCM_24')\n",
        "  if os.path.isfile(file_out):\n",
        "    audio_player(generated_audio, sr=sr)\n",
        "    print()\n",
        "    op(c.ok, 'Saved as', file_out.replace(drive_root, ''), time=True)\n",
        "  else:\n",
        "    op(c.fail, 'Error saving', file_out.replace(drive_root, ''), time=True)\n",
        "  \n",
        "# -- END THINGS --\n",
        "\n",
        "timer_end = time.time()\n",
        "\n",
        "print()\n",
        "op(c.okb, 'Elapsed', timedelta(seconds=timer_end-timer_start), time=True)\n",
        "op(c.ok, 'FIN.')"
      ],
      "metadata": {
        "id": "Znu4P-Gtsdrr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}